---
date: 2015-03-21
tags: 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- dummy-tags-should-be-replaced
author: 
layout: post
title: March Madness Prediction
excerpt: I apply a Bradley-Terry model to the NCAA basketball tournament.
categories: 
- sports
- statistics
featured: false
---
<p>
I generally don't invest much time exploring the connections between
statistics and sports <sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup>. But I though I'd take advantage of
the focus on NCAA basketball to introduce about some work I'd
previously done.
</p>

<div id="outline-container-orgd3e46ac" class="outline-2">
<h2 id="orgd3e46ac">Bradley Terry Model</h2>
<div class="outline-text-2" id="text-orgd3e46ac">
<p>
For a project in undergrad I modeled the MLB season using a Bradley
Terry model. The general idea is that each team is assigned a score,
\(\lambda_{i} > 0\). Then the probability that team \(i\) beats team \(j\) is simply
</p>

<p>
\[ \frac{\lambda_{i}}{\lambda_{i} + \lambda_{j}} \]
</p>

<p>
That's it; the model is incredibly simplistic. There exist variants
to allow for more complex models, but I'll stick with the simplest.
</p>
</div>
</div>

<div id="outline-container-orgfa64a30" class="outline-2">
<h2 id="orgfa64a30">Fitting the Model</h2>
<div class="outline-text-2" id="text-orgfa64a30">
<p>
We now have the task of fitting the model. There are options here:
you can fit maximum likelihood using an iterative process, or you
can take the Bayesian route. Since I was taking a Bayesian class,
it's clear what way I went.
</p>

<p>
However, fitting this model gets a little tricky. The problem is
that we don't have easy conjugacy to create a Gibbs sampler.
However, no problem, we can always use Metropolis-Hastings sampling.
Unfortunately, this didn't work very well. I was writing poor R
code, things were slow, and I couldn't get it to converge. With the
deadline looming, I needed to try something different.
</p>

<p>
Then I found this paper: <a href="http://arxiv.org/abs/1011.1761">Efficient Bayesian Inference for
Generalized Bradley-Terry Models</a>. It turns out you can write a Gibbs
sampler for this model, you just need to introduce the right latent
variables. It reframes the contest as follows: 
</p>

<p>
Let \(Y_{ki} \sim \text{Exp}(\lambda_{i})\) be the arrival time for
team \(i\). A game then is a race, with the team arriving first
winning. Using the properties of exponentials we see that
</p>

<p>
\[ \Pr(Y_{ki} > Y_{kj}) = \frac{\lambda_{i}}{\lambda_{i} + \lambda_{j}} \]
</p>

<p>
we then introduce the latent variable
</p>

<p>
\[ Z_{ij} = \sum_{k=1}^{n_{ij}} \min(Y_{kj}, Y_{ki}) \] 
</p>

<p>
which is simply the sum of the winning arrival times for each of the
\(n_{ij}\) times team \(i\) and \(j\) played. Again by the properties of
exponential distributions we know that this follows a
\(\text{Gamma}(n_{ij}, \lambda_{i} + \lambda_{j})\).
</p>

<p>
Couple this with a \(\text{Gamma}(a,b)\) prior on the \(\lambda_{i}\) we
can create a nice Gibbs sampler with the following conditionals.
</p>

<p>
\[ Z_{ij} | D, \lambda \sim \text{Gamma}(n_{ij}, \lambda_{i} + \lambda_{j}) \]
\[ \lambda_{i} \mid D, Z \sim \text{Gamma}(a + w_{i}, b + \sum_{i < j} Z_{ij} + \sum_{j < i} Z_{ji}) \]
</p>

<p>
where \(w_{i}\) is the number of games team \(i\) won.
</p>

<p>
Somewhere along the way I lost the R code, so I decided to rewrite
it using Julia. The code is hosted at this <a href="http://github.com/minimallysufficient/bradleyterry">repository</a>. 
</p>

<p>
Using data from <a href="https://www.spreadsheet-sports.com/2015-ncaa-basketball-game-data">spreadsheet-sports.com</a> we can scrape all of the game
scores for the current and the calculation of summary stats is
straightforward.
</p>
</div>
</div>

<div id="outline-container-org71b79d1" class="outline-2">
<h2 id="org71b79d1">Results</h2>
<div class="outline-text-2" id="text-org71b79d1">
<p>
In this season of March Madness, the obvious question is, what team
does this model think is the best team in the NCAA? We can draw from
the posterior and see which team is ranked highest. The result is
summarized in the following table:
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />
</colgroup>
<tbody>
<tr>
<td class="org-left">Team</td>
<td class="org-right">\(\Pr(\text{Team is best})\)</td>
</tr>

<tr>
<td class="org-left">Kentucky</td>
<td class="org-right">0.516</td>
</tr>

<tr>
<td class="org-left">Villanova</td>
<td class="org-right">0.115</td>
</tr>

<tr>
<td class="org-left">Wisconsin</td>
<td class="org-right">0.107</td>
</tr>

<tr>
<td class="org-left">Virginia</td>
<td class="org-right">0.073</td>
</tr>

<tr>
<td class="org-left">Gonzaga</td>
<td class="org-right">0.062</td>
</tr>

<tr>
<td class="org-left">Duke</td>
<td class="org-right">0.054</td>
</tr>

<tr>
<td class="org-left">Arizona</td>
<td class="org-right">0.049</td>
</tr>

<tr>
<td class="org-left">Notre Dame</td>
<td class="org-right">0.014</td>
</tr>

<tr>
<td class="org-left">Northern Iowa</td>
<td class="org-right">0.007</td>
</tr>

<tr>
<td class="org-left">Kansas</td>
<td class="org-right">0.003</td>
</tr>
</tbody>
</table>

<p>
Thus it's clear that Kentucky is heavily favored. This is an
unavoidable consequence of using only win record in our model. Since
they're undefeated, they are going to have a large \(\lambda_{i}\); in fact,
using maximum likelihood we would have \(\lambda_{i} = \infty\).
</p>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
And of course, I didn't even find the time to get this post
out before the tournament started.
</p></div></div>


</div>
</div>
