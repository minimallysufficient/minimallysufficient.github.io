---
date: 2016-05-22
tags: 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- dummy-tags-should-be-replaced
author: 
layout: post
title: Correlation Chains
excerpt: I investigate SMBC's novel correlation-chain methodology.
categories: 
- statistics
- humor
featured: false
---

<div id="outline-container-org19cace5" class="outline-2">
<h2 id="org19cace5">Correlation Chains</h2>
<div class="outline-text-2" id="text-org19cace5">
<p>
SMBC had a interesting <a href="http://www.smbc-comics.com/index.php?id=4106">comic</a> recently on correlation chains. It
suggests the new "Funtime Activity" of creating correlation chains.
As a statistician, I naturally wanted to evaluate the methodology.
</p>

<p>
The basic idea is that you start with a given variable X<sub>1</sub> ("Amount
of Sex" in the comic) and start by linking to a positively
correlated variable X<sub>2</sub> ("Happiness"). Then X<sub>2</sub> is positively
correlated to X<sub>3</sub> ("Income") so you expand the chain to X<sub>1</sub>
&rarr; X<sub>2</sub> &rarr; X<sub>3</sub>. Eventually you end up at variable X<sub>n</sub>
("Likelihood that you are, in fact, J.K. Rowling") that's you
conclude is positively correlated the variable X<sub>1</sub>.
</p>

<p>
Incidentally, this isn't the first time this topic has <a href="http://www.smbc-comics.com/?id=2860">appeared</a> on
SMBC.
</p>
</div>

<div id="outline-container-org424880d" class="outline-3">
<h3 id="org424880d">Intuition</h3>
<div class="outline-text-3" id="text-org424880d">
<p>
On a intuitive level, correlation chaining seems plausible. The
hand-wavy idea of correlation is that I can more or less replace one
variable with another without losing too much information. Thus I
should be able to just substitute variables right on down the line
without much change. To put it in technical terms, we have some
intuition that correlation is transitive such that if A is
correlated with B, and B is correlated with B, then A is correlated
with C.
</p>

<p>
This intuition is mostly correct, although in general it is false.
For vectors with <i>sufficiently strong</i> correlation, we can perform
this chaining <i>for a while</i> and still have a valid inference.
Unfortunately, the qualifications of <i>sufficiently strong</i> and <i>for
a while</i> are quite restrictive.
</p>
</div>
</div>

<div id="outline-container-org2e5686e" class="outline-3">
<h3 id="org2e5686e">Example</h3>
<div class="outline-text-3" id="text-org2e5686e">
<p>
Just to provide a concrete example, consider the following
correlation chain.
</p>

<div class="LaTeX">
\begin{eqnarray*}
  X_{1} &=& [1, 2, -3] \\
  X_{2} &=& [3, -1, -2] \\
  X_{3} &=& [2, -3, 1] \\
  X_{4} &=& [-1, -2, 3]
\end{eqnarray*}

</div>

<p>
You can check that 
</p>

<p>
\[ \operatorname{Cor}[X_{1}, X_{2}] = \operatorname{Cor}[X_{2}, X_{3}] = \operatorname{Cor}[X_{3}, X_{4}] = 0.5 \]
</p>

<p>
while 
</p>

<p>
\[ \operatorname{Cor}[X_{1}, X_{4}] = -1 \].
</p>

<p>
So, we have our counterexample; correlation chains can fail
dramatically, ending up at a perfectly anticorrelated vector. This
also occurred quite quickly for a rather strong correlation which
hints at how restrictive our conditions are going to have to be.
</p>
</div>
</div>
</div>

<div id="outline-container-orgf902fba" class="outline-2">
<h2 id="orgf902fba">Nerdy Details</h2>
<div class="outline-text-2" id="text-orgf902fba">
<p>
What exactly can we say about correlation chains? Of particular
interest is the the worst-case and average-case number of links we
can have before encountering an anti-correlated variable. Along the
way, we'll learn a bit about a geometric interpretation of
correlation and how to sample variables with a specific correlation.
</p>
</div>

<div id="outline-container-org6638e43" class="outline-3">
<h3 id="org6638e43">Correlation is just cosines</h3>
<div class="outline-text-3" id="text-org6638e43">
<p>
The first thing that we need to notice is that correlation is just
the cosine of the angle between two vectors. To see this, let's
just look at the formula for correlation.
</p>

<div class="LaTeX">
\begin{eqnarray*}
  \operatorname{Cor}[X, Y] &=& \frac{<x - \bar{x}, y - \bar{y}>}{|x -\bar{x}||y - \bar{y}|} \\
             &=& \frac{|x - \bar{X}||y - \bar{y}|\cos{\theta}}{|x -\bar{x}||y - \bar{y}|} \\
             &=& cos(\theta)
\end{eqnarray*}

</div>

<p>
So now let's think about that special case I started with. If you
look really carefully, it's clear how I generated this data.
Starting with the first vector, I just cycle the entries of the
vector and flip the sign. If you can visualize 3 dimensional space,
you'll notice that this is just a rotation of &pi; / 3.
</p>
</div>
</div>

<div id="outline-container-org1b5d4d4" class="outline-3">
<h3 id="org1b5d4d4">How many links can we make in the worst case?</h3>
<div class="outline-text-3" id="text-org1b5d4d4">
<p>
So how can we minimize the correlation between vectors \(A\) and \(C\)?
It's exactly the case when vector \(C\) is rotated exactly
\(\arccos(\rho_{AB}) + \arccos(\rho_{BC})\) degrees from from A. 
</p>

<p>
Then if we have a fixed correlation, the worst case is that we keep
on rotating an angle of \(\arccos{\rho}\) for each link. Thus the chain
will reach an anticorrelated vector in \(\pi / \arccos{\rho}\) links.
Recalling the example chain which had correlation 0.5, the chain
reached the perfectly anticorrelated vector in exactly \(\pi /
   \arccos(0.5) = 3\) links. More generally, let's look at the minimal
number of links as a function of the correlation.
</p>


<div class="figure">
<p><img src="/img/correlation_worst_case_links.png" alt="correlation_worst_case_links.png" />
</p>
</div>

<p>
The main takeaway from this graph is that you need fairly strong
correlation to have more than a couple links in the chain. However,
once you have very strong correlations like 0.9999, you can make a
lot of links in the chain as the function asymptotes to infinity.
If you want to be able to do \(n\) links, you need a correlation as
strong as \(\cos(pi / n)\). So for 5 links you need correlations of at
least 0.8. For 1000 links, you need correlations of at least
0.99999.
</p>
</div>
</div>

<div id="outline-container-org0950769" class="outline-3">
<h3 id="org0950769">How to sample vectors with a given correlation</h3>
<div class="outline-text-3" id="text-org0950769">
<p>
I don't particularly want to do the math for the average-case, so
the remainder of our results will rely upon simulations. To do this
I need to sample uniformly from all vectors with the right
correlation. To make this easier, we instead sample uniformly from
the unit n-sphere. This is fine because correlation doesn't depend
upon scaling so we can just work with unit vectors.
</p>

<p>
Sampling from the unit n-sphere is quite easy. You sample from a
multivariate normal with spherical covariance and scale the vector
appropriately.
</p>

<p>
But now we need to get the correlation correct. The idea here is
that we need to get our vector and a vector orthogonal to our
vector. As a nice connection to statistics, this is just the
residuals of the regression.
</p>

<p>
\[ \epsilon_{} = (I_{n} - x(x^{T}x)^{-1}x^{T}) %*% y \]
</p>

<p>
We'll scale this vector so it lies on the n-sphere. Now we just
need to rotate the starting vector the appropriate angle. Some
basic trigonometry will tell us that we should use the scaling:
</p>

<p>
\[ \sin(\theta) \epsilon + \cos(\theta) x \]
</p>

<p>
Which, because \(\rho = \cos(\theta)\) can simplify to become
</p>

<p>
\[ \sqrt{1 - \rho^{2}} \epsilon + \rho x \]
</p>

<p>
If you want to verify that this works, try the following R code:
</p>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #ff1493;">sample_correlated</span> <span style="color: #96CBFE;">&lt;-</span> <span style="color: #4c83ff;">function</span>(x, cor) {
    n <span style="color: #96CBFE;">&lt;-</span> length(x)
    x <span style="color: #96CBFE;">&lt;-</span> scale(x) 

    <span style="color: #8B8989; font-style: italic;">## </span><span style="color: #8B8989; font-style: italic;">x(x^{T}x)^{-1}x^{T}</span>
    Q <span style="color: #96CBFE;">&lt;-</span> qr.Q(qr(x))
    P <span style="color: #96CBFE;">&lt;-</span> tcrossprod(Q)

    y <span style="color: #96CBFE;">&lt;-</span> rnorm(n)
    y <span style="color: #96CBFE;">&lt;-</span> (diag(n)-P) <span style="color: #96CBFE;">%*%</span> y
    y <span style="color: #96CBFE;">&lt;-</span> scale(y)
    y <span style="color: #96CBFE;">&lt;-</span> sqrt(1 - cor^2) * y + cor * x

    <span style="color: #4c83ff;">return</span>(y)
}
</pre>
</div>
</div>
</div>

<div id="outline-container-orga783ccd" class="outline-3">
<h3 id="orga783ccd">Simulating a correlation chain</h3>
<div class="outline-text-3" id="text-orga783ccd">
<p>
Once we've simulated a single variable, we can start simulating the
entire correlation chain. Here's a figure of an example chain where
the correlation is 0.5.
</p>


<div class="figure">
<p><img src="/img/sampled-correlation-chain.png" alt="sampled-correlation-chain.png" />
</p>
</div>

<p>
As we can see, the correlation chain isn't particularly compelling.
We see some relationship in the first iteration, but by a few
iterations we're getting more or less uncorrelated relationships.
On iteration 6 we reach our first anti-correlated variable, twice
the number of the worst-case.
</p>
</div>
</div>

<div id="outline-container-org6a23964" class="outline-3">
<h3 id="org6a23964">Average number of links until the first anticorrelated variable</h3>
<div class="outline-text-3" id="text-org6a23964">
<p>
Now that we can sample from this distribution, let's see how long
it's going to take us on average to get to an anticorrelated
variable.
</p>


<div class="figure">
<p><img src="/img/average_case_links.png" alt="average_case_links.png" />
</p>
</div>

<p>
It seems that we have a dependence upon the dimension. This makes
sense; if I rotate on a circle, I don't have many places to go. But
if I rotate on a sphere, I have lots of different places to go. With
n dimensions I have a even more.
</p>
</div>
</div>
</div>

<div id="outline-container-org30a5a29" class="outline-2">
<h2 id="org30a5a29">Takeaway</h2>
<div class="outline-text-2" id="text-org30a5a29">
<p>
So the ability to use correlation chains depends heavily upon the
strength of the relationships and the number of links. If we have
highly correlated variables, we can get away with a few links before
things break down. Otherwise, we have no guarantees that our
endpoint is positively correlated.
</p>
</div>

<div id="outline-container-orga8d86b6" class="outline-3">
<h3 id="orga8d86b6">What does this mean for the correlation chain in the SMBC comic?</h3>
<div class="outline-text-3" id="text-orga8d86b6">
<p>
Unfortunately, it doesn't look good. Lets look at the chain.
</p>

<ol class="org-ol">
<li>Amount of Sex</li>
<li>Happiness</li>
<li>Income</li>
<li>Likelihood of owning a signed copy of a Harry Potter novel</li>
<li>Number of possessions that J.K Rowling has touched</li>
<li>Likelihood that you are, in fact, J.K. Rowling</li>
</ol>

<p>
We're technically making 5 links since the connection between 4 and
5 is omitted in the comic. For 5 links with equal correlation, we
need correlations above 0.8. I doubt that any of these
relationships are correlated at the 0.8 level, so it's possible for
the correlation to actually be negative. However, if we look at the
average case (assuming generous correlations of 0.5), we see we're
somewhat more likely to have a positive correlation than a negative
correlation, but not by much. It certainly isn't good enough to
feel confident about our conclusions.
</p>


<div class="figure">
<p><img src="/img/correlation_after_links.png" alt="correlation_after_links.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org610c6f4" class="outline-3">
<h3 id="org610c6f4">Correlation is not causation</h3>
<div class="outline-text-3" id="text-org610c6f4">
<p>
I would be remiss if I didn't add a final parting caveat. Everything
above just deals with correlation; this is quite different from
causation. Causation is tricky stuff and I should really read more
about it. But I would assume that, at the very least, to support a
causal claim based upon a correlation chain that each link has to be
causal.
</p>

<p>
So the final panel? It seems to make a causal claim that the
likelihood that you're JK Rowling increases your amount of sex. A
recent CMU <a href="http://www.sciencedirect.com/science/article/pii/S0167268115001316">study</a> suggests that the link between sex and happiness is
not causal. Since the first link in the chain isn't causal, the
conclusion is just not supported by the data. I expect <a href="https://xkcd.com/552/">better</a> from
my web comics ;).
</p>
</div>
</div>
</div>
